# -*- coding: utf-8 -*-
"""CLASSIFICACAO.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ByDAnKfTHq6jEdYUc6YaEdHNC4qNONlC

EXEMPLO
"""

from sklearn.naive_bayes import GaussianNB

# Dados de exemplo
X = [[100, 20], [150, 30], [120, 25], [140, 28]]
y = ['Não Spam', 'Spam', 'Não Spam', 'Spam']

# Treinando o modelo
model = GaussianNB()
model.fit(X, y)

# Previsão para um novo e-mail
novo_email = [[130, 22]]
resultado = model.predict(novo_email)
print(f"Previsão para o novo e-mail: {resultado[0]}")

"""NAIVE BAYES"""

# Passo 1: Importar as bibliotecas necessárias
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

# Passo 2: Preparar os dados
# Suponha que temos um conjunto de dados com e-mails e seus rótulos (spam ou não spam)
emails = [
    "Oferta imperdível! Ganhe 50% de desconto em todos os produtos!",
    "Você ganhou um prêmio de R$ 18.000! Clique aqui para resgatar.",
    "Confira as novas ofertas da loja. Não perca!",
    "Reunião de equipe amanhã às 10h. Por favor, confirme sua presença.",
    "Lembrete: pagamento da fatura do cartão de crédito vence amanhã.",
]
labels = [1, 1, 0, 0, 0] # 1 para spam, 0 para não spam

# Passo 3: Transformar os dados em uma matriz de contagem de palavras (bag of words)
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(emails)

# Passo 4: Dividir os dados em conjunto de treinamento e conjunto de teste
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)

# Passo 5: Criar e treinar o modelo
model = MultinomialNB() # Criar o modelo Naive Bayes multinomial
model.fit(X_train, y_train) # Treinar o modelo com os dados de treinamento

# Passo 6: fazer previsões
predictions = model.predict(X_test) # Fazer previsões usando o conjunto de teste

# Passo 7: Avaliar a precisão do modelo
accuracy = accuracy_score(y_test, predictions) # Calcular a precisão do modelo
print("Accuracy:", accuracy)

"""KNN"""

# Passo 1: Importar as bibliotecas necessárias
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Passo 2: Preparar os dados
# Suponha que temos um conjunto de dados com e-mails e seus rótulos (spam ou não spam)
# Aqui está um exemplo simples de um conjunto de dados fictício:
emails = [
    "Oferta imperdível! Ganhe 50% de desconto em todos os produtos!",
    "Você ganhou um prêmio de R$ 18.000! Clique aqui para resgatar.",
    "Confira as novas ofertas da loja. Não perca!",
    "Reunião de equipe amanhã às 10h. Por favor, confirme sua presença.",
    "Lembrete: pagamento da fatura do cartão de crédito vence amanhã.",
]
labels = [1, 1, 0, 0, 0] # 1 para spam, 0 para não spam

# Passo 3: Transformar os dados em uma matriz de contagem de palavras (bag of words)
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(emails)

# Passo 4: Dividir os dados em conjunto de treinamento e conjunto de teste
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)

# Passo 5: Criar e treinar o modelo KNN
model = KNeighborsClassifier(n_neighbors=3) # Criar o modelo KNN com 3 vizinhos
model.fit(X_train, y_train) # Treinar o modelo com os dados de treinamento

# Passo 6: Fazer previsões
predictions = model.predict(X_test) # Fazer previsões usando o conjunto de teste

# Passo 7: Avaliar a precisão do modelo
accuracy = accuracy_score(y_test, predictions) # Calcular a precisão do modelo
print("Accuracy:", accuracy)

"""SVN"""

# Passo 1: Importar as bibliotecas necessárias
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Passo 2: Preparar os dados
# Suponha que temos um conjunto de dados com e-mails e seus rótulos (spam ou não spam)
# Aqui está um exemplo simples de um conjunto de dados fictício:
emails = [
    "Oferta imperdível! Ganhe 50% de desconto em todos os produtos!",
    "Você ganhou um prêmio de R$ 18.000! Clique aqui para resgatar.",
    "Confira as novas ofertas da loja. Não perca!",
    "Reunião de equipe amanhã às 10h. Por favor, confirme sua presença.",
    "Lambrete: pagamento da fatura do cartão de crédito vence amanhã.",
]
labels = [1, 1, 0, 0, 0] # 1 para spam, 0 para não spam

# Passo 3: Transformar os dados em uma matriz de contagem de palavras (bag of words)
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(emails)

# Passo 4: Dividir os dados em conjunto de treinamento e conjunto de teste
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)

# Passo 5: Criar e treinar o modelo SVM
model = SVC(kernel='linear') # Criar o modelo SVM com kernel linear
model.fit(X_train, y_train) # Treinar o modelo com os dados de treinamento

# Passo 6: Fazer previsões
predictions = model.predict(X_test) # Fazer previsões usando o conjunto de teste

# Passo 7: Avaliar a precisão do modelo
accuracy = accuracy_score(y_test, predictions) # Calcular a precisão do modelo
print("Accuracy:", accuracy)

"""TREE DECISION"""

# Passo 1: Importar as bibliotecas necessárias
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Passo 2: Preparar os dados
# Suponha que temos um conjunto de dados com e-mails e seus rótulos (spam ou não spam)
# Aqui está um exemplo simples de um conjunto de dados fictício:
emails = [
    "Oferta imperdível! Ganhe 50% de desconto em todos os produtos!",
    "Você ganhou um prêmio de R$ 18.000! Clique aqui para resgatar.",
    "Confira as novas ofertas da loja. Não perca!",
    "Reunião de equipe amanhã às 10h. Por favor, confirme sua presença.",
    "Lambrete: pagamento da fatura do cartão de crédito vence amanhã.",
]
labels = [1, 1, 0, 0, 0] # 1 para spam, 0 para não spam

# Passo 3: Transformar os dados em uma matriz de contagem de palavras (bag of words)
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(emails)

# Passo 4: Dividir os dados em conjunto de treinamento e conjunto de teste
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)

# Passo 5: Criar e treinar o modelo de Árvore de Decisão
model = DecisionTreeClassifier() # Criar o modelo de Árvore de Decisão
model.fit(X_train, y_train) # Treinar o modelo com os dados de treinamento

# Passo 6: Fazer previsões
predictions = model.predict(X_test) # Fazer previsões usando o conjunto de teste

# Passo 7: Avaliar a precisão do modelo
accuracy = accuracy_score(y_test, predictions) # Calcular a precisão do modelo
print("Accuracy:", accuracy)